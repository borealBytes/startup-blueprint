# Task 1: Triage - Identify what broke
triage_failures:
  description: >
    Analyze CI job index AND scan logs for hidden errors. Many jobs report
    "success" in metadata but have errors in their logs.

    1. Call read_job_index() to get the full list of jobs.
    2. For EVERY job (not just failed ones):
       - Call read_job_summary(folder_name) for metadata
       - Call get_log_stats(folder_name) to check error/warning counts
       - Call check_log_size(folder_name) to determine reading strategy
    3. Identify jobs needing investigation:
       - Jobs with conclusion="failure" or "cancelled" (obvious failures)
       - Jobs with log_stats.errors > 0 (hidden failures, log has errors)
       - Jobs with log_stats.warnings > 10 (elevated warning count)
    4. Create structured investigation plan with:
       - Job name, folder, and why it needs investigation
       - Whether failure is from metadata or log analysis
       - Recommended log reading strategy based on size

    ⚠️ CRITICAL: Many CI jobs (especially format-and-lint) report "success"
    in job metadata but actually have errors in the log content. You MUST
    call get_log_stats() for every job to catch these hidden failures.

    Example from PR #15: core-ci reported "success" but had 77 stylelint
    errors + 1 sqlfluff FAIL in the actual log output.
  expected_output: >
    JSON-structured list of jobs needing investigation, including those with
    log errors even if metadata shows "success". Report ALL jobs where
    get_log_stats() shows errors or high warning counts.
  agent: ci_pipeline_lead

# Task 2: Investigation - Get the evidence
investigate_logs:
  description: >
    For each failed job identified in the triage phase, extract the specific
    error evidence.

    For each failed job: 1. Call check_log_size(folder_name) FIRST. 2. If log <
    50KB: Use read_full_log(folder_name). 3. If log > 50KB: Use
    search_log(folder_name, pattern) with smart patterns
       (e.g., "error", "exception", "failed", "fatal").
    4. Use get_log_stats(folder_name) to gauge error density.

    Do NOT analyze the root cause yet—just extract the raw exception traces and
    error messages.
  expected_output: >
    Detailed log snippets containing the specific error traces, stack dumps, or
    failure messages for each failed job.
  agent: log_pattern_specialist

# Task 3: Resolution - Explain and Fix
determine_root_cause:
  description: >
    Analyze the extracted log evidence to determine the technical root cause and
    provide fixes.

    For each error trace found: 1. Explain WHY it failed (e.g., "Missing
    dependency", "Syntax error", "Timeout"). 2. Provide a specific, actionable
    fix (e.g., "Add package X to package.json", "Fix typo in line 42"). 3.
    Classify severity (Critical/Warning).
  expected_output: >
    A structured analysis of each failure, including Root Cause, Fix
    Recommendation, and Severity.
  agent: error_resolution_specialist

# Task 4: Reporting - Final Summary
compile_ci_report:
  description: >
    Synthesize all findings into the final ci_summary.json file.

    1. Combine the triage status, log evidence, and root cause analysis. 2. Use
    CIOutputParserTool to get core CI status. 3. Use WorkspaceTool to read
    diff.json for context if needed. 4. Write the final JSON file using
    WorkspaceTool(operation="write", filename="ci_summary.json", ...).

    Required JSON structure: {
      "status": "success|warning|failure",
      "summary": "High-level summary",
      "jobs_analyzed": [...],
      "critical_errors": [{type, file, line, message, fix_suggestion, job}],
      "warnings": [...],
      "merge_status": "APPROVE|REQUEST_CHANGES",
      "merge_rationale": "..."
    }
  expected_output: >
    "Successfully wrote ci_summary.json with N critical errors and M warnings."
  agent: ci_pipeline_lead
